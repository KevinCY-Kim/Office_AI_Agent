{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d391781",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alpaco/anaconda3/envs/test/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import tiktoken\n",
    "import os, re, json, glob, torch\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForCausalLM, pipeline,\n",
    "    AutoModelForSequenceClassification\n",
    ")\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from docx import Document\n",
    "from docx.shared import Pt\n",
    "from docx.oxml.ns import qn\n",
    "from PyPDF2 import PdfReader\n",
    "import gc\n",
    "\n",
    "GUIDELINE_FILE = \"/home/alpaco/autosry/rnd_guideline.json\"\n",
    "RAG_JSON_FILES = [\"/home/alpaco/autosry/rag_chunks500_50.json\"]\n",
    "LAW_DIR = \"/home/alpaco/autosry/reference_file\"\n",
    "\n",
    "E5_NAME = \"intfloat/multilingual-e5-large\"\n",
    "GEN_NAME = \"skt/A.X-4.0-Light\"\n",
    "NLI_MODEL = \"MoritzLaurer/multilingual-MiniLMv2-L6-mnli-xnli\"\n",
    "\n",
    "DEVICE = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# GPU 메모리 감지 → 안전 토큰 설정\n",
    "GEN_MAX_NEW_TOKENS = 3000\n",
    "if torch.cuda.is_available():\n",
    "    free, total = torch.cuda.mem_get_info()\n",
    "    if total < 12 * 1024**3:  # 12GB 미만 GPU는 토큰 수 축소\n",
    "        GEN_MAX_NEW_TOKENS = 1500\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "GEN_DO_SAMPLE = False\n",
    "\n",
    "def first_n_lines(text: str, n_chars=400):\n",
    "    t = \" \".join(str(text).split())\n",
    "    return t[:n_chars]\n",
    "\n",
    "def clean_generated_text(text: str) -> str:\n",
    "    text = re.sub(r'[•●▪▶◇◆□▪️▫️–]', ' ', text)\n",
    "    text = re.sub(r'^\\s*[-#*]+\\s*', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\n{3,}', '\\n\\n', text)\n",
    "    text = re.sub(r'\\s+([\\.,;:])', r'\\1', text)\n",
    "    return text.strip()\n",
    "\n",
    "def has_number(text: str):\n",
    "    return bool(re.search(r\"\\d\", text))\n",
    "\n",
    "sections = [\n",
    "    {\"section\": \"연구기획과제의 개요\",\n",
    "        \"role\": \"제안서 총괄 에디터\",\n",
    "        \"query\": \"과제의 목적, 필요성, 기대효과를 논리적으로 연결하여 핵심 내용을 500자 내외로 명료하게 요약함. 평가자가 과제의 전체 구조를 한눈에 이해할 수 있도록 기술함.\",\n",
    "        \"constraints\": [\"500자 내외\", \"논리적 연결 구조 유지\", \"핵심 요약 중심\"],\n",
    "        \"output_format\": \"서술문\"},\n",
    "    {\"section\": \"연구개발과제의 배경\",\n",
    "        \"role\": \"R&D 기획 전문가\",\n",
    "        \"query\": \"제공된 선행연구, 시장 동향, 정책자료를 근거로 본 과제가 추진되어야 하는 당위성과 RFP(공고문) 부합성을 논리적으로 제시함.\",\n",
    "        \"constraints\": [\"데이터 근거 포함\", \"RFP 문항 부합성 명시\"],\n",
    "        \"output_format\": \"서술문\"},\n",
    "    {\"section\": \"연구개발과제의 필요성\",\n",
    "        \"role\": \"산업분석가\",\n",
    "        \"query\": \"데이터와 사례를 근거로 현재 기술적·산업적 문제점을 제시하고, 본 과제가 이를 해결해야 하는 필요성을 인과적으로 서술함.\",\n",
    "        \"constraints\": [\"인과관계 구조\", \"데이터 근거 제시\"],\n",
    "        \"output_format\": \"서술문\"},\n",
    "    {\"section\": \"기술개발 핵심어(키워드)\",\n",
    "        \"role\": \"기술 네이밍 전략가\",\n",
    "        \"query\": \"과제의 정체성과 핵심 기술을 대표하는 키워드 5개를 국문·영문 공식 명칭으로 제시함. 각 용어는 국제 표준 또는 학술 정의를 근거로 하며, 선정 사유를 간단히 명시함.\",\n",
    "        \"constraints\": [\"국문·영문 병기\", \"국제 표준 기반 정의 포함\", \"5개 이내\"],\n",
    "        \"output_format\": \"표(키워드/영문명/정의/출처)\"},\n",
    "    {\"section\": \"연구개발 목표\",\n",
    "        \"role\": \"R&D PMO\",\n",
    "        \"query\": \"과제의 최종 목표를 500자 내외로 명확히 기술함. 핵심 성능지표(KPI), 달성 기준(수치·단위·마일스톤), 검증 방법을 포함하며, 모호한 표현은 사용하지 않음.\",\n",
    "        \"constraints\": [\"정량화된 수치 포함\", \"KPI 및 검증방법 명시\"],\n",
    "        \"output_format\": \"서술문 + 표(KPI/단위/기준/검증방법)\"},\n",
    "        {\"section\": \"연구개발 내용\",\n",
    "            \"role\": \"기술총괄자(Tech Lead)\",\n",
    "            \"query\": \"전체 연구 범위를 1,000자 내외로 체계적으로 기술함. 핵심 기술요소, 세부 과제 구조, 데이터 및 시스템 흐름, 성능 평가 계획을 명시함.\",\n",
    "            \"constraints\": [\"1,000자 내외\", \"기술요소 및 평가계획 포함\"],\n",
    "            \"output_format\": \"서술문 + 도식(기술흐름)\"},\n",
    "        {\"section\": \"연차별 개발목표\",\n",
    "            \"role\": \"PMO 리더\",\n",
    "            \"query\": \"최종 목표 달성을 위한 연차별 및 기관별 개발 목표를 정량적으로 제시함. 각 연차별 KPI, 마일스톤, 검증 방법을 명확히 포함함.\",\n",
    "            \"constraints\": [\"연차별 구분\", \"정량적 지표 포함\"],\n",
    "            \"output_format\": \"표(연차/KPI/마일스톤/검증방법)\"},\n",
    "        {\"section\": \"연차별 개발내용 및 범위\",\n",
    "        \"role\": \"공동연구 컨소시엄 코디네이터\",\n",
    "        \"query\": \"참여 기관별 역할, 책임, 연차별 산출물을 중복 및 누락 없이 기술함. 공동기관이 없는 경우 해당 항목은 생략함.\",\n",
    "        \"constraints\": [\"기관별 역할 명확화\", \"중복/누락 금지\"],\n",
    "        \"output_format\": \"표(기관/역할/산출물/책임)\"},\n",
    "        {\"section\": \"추진방법 및 전략\",\n",
    "            \"role\": \"총괄 아키텍트(Chief Architect)\",\n",
    "            \"query\": \"핵심 기술개발 방법론, 예측 가능한 리스크와 대응 방안, 성능 검증 계획을 논리적으로 제시함. 기술의 우수성과 실현 가능성을 입증함.\",\n",
    "            \"constraints\": [\"핵심 방법론 포함\", \"리스크 및 검증계획 명시\"],\n",
    "            \"output_format\": \"서술문 + 표(리스크/대응방안)\"},\n",
    "        {\"section\": \"과제 성과의 활용방안\",\n",
    "            \"role\": \"사업개발 총괄(BD Head)\",\n",
    "            \"query\": \"연구 성과가 실제 산업 및 시장에서 어떻게 활용될 수 있는지를 구체적으로 제시함. 목표 시장, 주요 수요처, 핵심 적용 시나리오, 기술의 차별화된 가치를 중심으로 사업화 방향을 설명함.\",\n",
    "            \"constraints\": [\"시장 시나리오 포함\", \"Value Proposition 중심\"],\n",
    "            \"output_format\": \"서술문 + 표(시장/수요처/적용시나리오)\"},\n",
    "        {\"section\": \"신규사업 신설의 기대효과\",\n",
    "            \"role\": \"거시경제 분석가(Macro-Economic Analyst)\",\n",
    "            \"query\": \"본 과제가 국가 경제에 미치는 파급효과를 정량적 지표로 제시함. 시장 창출, 수입 대체, 수출 증대, 일자리 창출 등 거시적 효과를 수치로 증명함.\",\n",
    "            \"constraints\": [\"정량적 수치 기반\", \"경제효과 명시\"],\n",
    "            \"output_format\": \"표(지표/예상값/근거자료)\"},\n",
    "        {\"section\": \"사회적 가치 창출 계획\",\n",
    "            \"role\": \"사회적 가치 전략가(Social Value Strategist)\",\n",
    "            \"query\": \"과제의 사회적 비전과 목표를 정의하고, 이를 달성하기 위한 구체적인 실행 로드맵을 수립함. 보건, 환경, 안전 등 사회적 가치 범주와 연계함.\",\n",
    "            \"constraints\": [\"사회적 가치 범주 명시\", \"로드맵 포함\"],\n",
    "            \"output_format\": \"서술문 + 표(목표/실행단계/성과지표)\"},\n",
    "        {\"section\": \"사회적 가치창출의 기대효과\",\n",
    "            \"role\": \"임팩트 평가 전문가(Impact Assessor)\",\n",
    "            \"query\": \"사회적 가치 창출 계획이 실행되었을 때 예상되는 긍정적 변화를 정량적 및 정성적 임팩트 지표로 제시함. 사회적 파급효과를 객관적으로 설명함.\",\n",
    "            \"constraints\": [\"정량/정성 지표 병기\", \"사회적 파급효과 포함\"],\n",
    "            \"output_format\": \"표(지표유형/성과/측정방법)\"},\n",
    "        {\"section\": \"경제적 성과창출의 기대효과\",\n",
    "            \"role\": \"최고재무책임자(CFO)\",\n",
    "            \"query\": \"기업 관점에서 본 과제의 재무적 성과를 구체적 수치와 함께 제시함. 예상 매출, 이익, 투자수익률(ROI), 순현재가치(NPV) 등 주요 지표를 근거와 함께 명료하게 기술함.\",\n",
    "            \"constraints\": [\"재무지표 포함\", \"산출근거 명시\"],\n",
    "            \"output_format\": \"표(지표/예상값/근거)\"},\n",
    "        {\"section\": \"신규 인력 채용 계획 및 활용 방안\",\n",
    "            \"role\": \"전략적 인사 파트너(Strategic HR Partner)\",\n",
    "            \"query\": \"과제 수행에 필요한 핵심 인력의 채용, 배치, 교육 계획을 타임라인과 함께 제시함. 인력 확보 및 역량 극대화 방안을 구체적으로 기술함.\",\n",
    "            \"constraints\": [\"타임라인 포함\", \"역량 강화 계획 명시\"],\n",
    "            \"output_format\": \"표(직무/채용시점/교육계획)\"},\n",
    "        {\"section\": \"보안등급의 분류 및 해당 사유\",\n",
    "            \"role\": \"보안관리 책임자(Security Manager)\",\n",
    "            \"query\": \"관련 법령 및 보안관리요령을 근거로 본 과제의 보안등급을 분류하고, 그 결정 사유를 간결하고 명확하게 기술함.\",\n",
    "            \"constraints\": [\"법령 근거 포함\", \"사유 명시\"],\n",
    "            \"output_format\": \"서술문\"}\n",
    "        ]\n",
    "\n",
    "CHUNK_MAX = 500\n",
    "CHUNK_OVERLAP = 50\n",
    "TOPK = 5\n",
    "REF_WEIGHTS = {\n",
    "    \"행정업무의 운영 및 혁신에 관한 규정(대통령령)\": 0.30,\n",
    "    \"행정업무의 운영 및 혁신에 관한 규정 시행규칙\": 0.30,\n",
    "    \"국가연구개발사업 연구개발계획서\": 0.20,\n",
    "    \"전략계획서 작성안내서\": 0.10,\n",
    "    \"Vertical\": 0.10\n",
    "}\n",
    "DEFAULT_WEIGHT = 0.05\n",
    "\n",
    "def guess_weight(filename: str) -> float:\n",
    "    for k, w in REF_WEIGHTS.items():\n",
    "        if k.lower() in filename.lower():\n",
    "            return w\n",
    "    return DEFAULT_WEIGHT\n",
    "\n",
    "def chunk_text(txt: str, max_chars=CHUNK_MAX, overlap=CHUNK_OVERLAP):\n",
    "    txt = \" \".join(str(txt).split())\n",
    "    chunks = []\n",
    "    i = 0\n",
    "    while i < len(txt):\n",
    "        j = min(len(txt), i + max_chars)\n",
    "        chunks.append(txt[i:j])\n",
    "        if j == len(txt): break\n",
    "        i = max(0, j - overlap)\n",
    "    return chunks\n",
    "\n",
    "def load_reference_chunks(law_dir: str):\n",
    "    gc.collect()  # 파이썬 객체 메모리 수거\n",
    "    with torch.cuda.device(1):\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.ipc_collect()\n",
    "    items = []\n",
    "    for p in glob.glob(os.path.join(law_dir, \"*\")):\n",
    "        text = \"\"\n",
    "        try:\n",
    "            ext = p.split(\".\")[-1].lower()\n",
    "            if ext == \"pdf\":\n",
    "                reader = PdfReader(p)\n",
    "                for pg in reader.pages:\n",
    "                    text += (pg.extract_text() or \"\") + \"\\n\"\n",
    "            elif ext in (\"docx\", \"doc\"):\n",
    "                d = Document(p)\n",
    "                text = \"\\n\".join([x.text for x in d.paragraphs])\n",
    "            elif ext in (\"rtf\", \"txt\"):\n",
    "                with open(p, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "                    text = f.read()\n",
    "        except Exception:\n",
    "            continue\n",
    "        base = os.path.basename(p)\n",
    "        weight = guess_weight(base)\n",
    "        for idx, ck in enumerate(chunk_text(text)):\n",
    "            items.append({\"source\": base, \"chunk_id\": idx, \"weight\": weight, \"text\": ck})\n",
    "    return items\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d773ee9e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m embed_model \u001b[38;5;241m=\u001b[39m SentenceTransformer(E5_NAME, device\u001b[38;5;241m=\u001b[39mDEVICE)\n\u001b[0;32m----> 2\u001b[0m REF_ITEMS \u001b[38;5;241m=\u001b[39m \u001b[43mload_reference_chunks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mLAW_DIR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m REF_EMBS \u001b[38;5;241m=\u001b[39m embed_model\u001b[38;5;241m.\u001b[39mencode(\n\u001b[1;32m      4\u001b[0m     [it[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m it \u001b[38;5;129;01min\u001b[39;00m REF_ITEMS],\n\u001b[1;32m      5\u001b[0m     convert_to_tensor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      6\u001b[0m     normalize_embeddings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[INFO] Loaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(REF_ITEMS)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m reference chunks.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 176\u001b[0m, in \u001b[0;36mload_reference_chunks\u001b[0;34m(law_dir)\u001b[0m\n\u001b[1;32m    174\u001b[0m     reader \u001b[38;5;241m=\u001b[39m PdfReader(p)\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pg \u001b[38;5;129;01min\u001b[39;00m reader\u001b[38;5;241m.\u001b[39mpages:\n\u001b[0;32m--> 176\u001b[0m         text \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[43mpg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m ext \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocx\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoc\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    178\u001b[0m     d \u001b[38;5;241m=\u001b[39m Document(p)\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.10/site-packages/PyPDF2/_page.py:1851\u001b[0m, in \u001b[0;36mPageObject.extract_text\u001b[0;34m(self, Tj_sep, TJ_sep, orientations, space_width, visitor_operand_before, visitor_operand_after, visitor_text, *args)\u001b[0m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(orientations, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m   1849\u001b[0m     orientations \u001b[38;5;241m=\u001b[39m (orientations,)\n\u001b[0;32m-> 1851\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_text\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1852\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1853\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1854\u001b[0m \u001b[43m    \u001b[49m\u001b[43morientations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1855\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspace_width\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1856\u001b[0m \u001b[43m    \u001b[49m\u001b[43mPG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCONTENTS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvisitor_operand_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1858\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvisitor_operand_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1859\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvisitor_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.10/site-packages/PyPDF2/_page.py:1356\u001b[0m, in \u001b[0;36mPageObject._extract_text\u001b[0;34m(self, obj, pdf, orientations, space_width, content_key, visitor_operand_before, visitor_operand_after, visitor_text)\u001b[0m\n\u001b[1;32m   1352\u001b[0m     content \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1353\u001b[0m         obj[content_key]\u001b[38;5;241m.\u001b[39mget_object() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_key, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m obj\n\u001b[1;32m   1354\u001b[0m     )\n\u001b[1;32m   1355\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content, ContentStream):\n\u001b[0;32m-> 1356\u001b[0m         content \u001b[38;5;241m=\u001b[39m \u001b[43mContentStream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbytes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1357\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:  \u001b[38;5;66;03m# it means no content can be extracted(certainly empty page)\u001b[39;00m\n\u001b[1;32m   1358\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.10/site-packages/PyPDF2/generic/_data_structures.py:877\u001b[0m, in \u001b[0;36mContentStream.__init__\u001b[0;34m(self, stream, pdf, forced_encoding)\u001b[0m\n\u001b[1;32m    875\u001b[0m     stream_bytes \u001b[38;5;241m=\u001b[39m BytesIO(stream_data_bytes)\n\u001b[1;32m    876\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforced_encoding \u001b[38;5;241m=\u001b[39m forced_encoding\n\u001b[0;32m--> 877\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__parse_content_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.10/site-packages/PyPDF2/generic/_data_structures.py:943\u001b[0m, in \u001b[0;36mContentStream.__parse_content_stream\u001b[0;34m(self, stream)\u001b[0m\n\u001b[1;32m    941\u001b[0m         peek \u001b[38;5;241m=\u001b[39m stream\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    942\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 943\u001b[0m     operands\u001b[38;5;241m.\u001b[39mappend(\u001b[43mread_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforced_encoding\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.10/site-packages/PyPDF2/generic/_data_structures.py:1036\u001b[0m, in \u001b[0;36mread_object\u001b[0;34m(stream, pdf, forced_encoding)\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mread_object\u001b[39m(\n\u001b[1;32m   1031\u001b[0m     stream: StreamType,\n\u001b[1;32m   1032\u001b[0m     pdf: Any,  \u001b[38;5;66;03m# PdfReader\u001b[39;00m\n\u001b[1;32m   1033\u001b[0m     forced_encoding: Union[\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mstr\u001b[39m, List[\u001b[38;5;28mstr\u001b[39m], Dict[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1034\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[PdfObject, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m, ContentStream]:\n\u001b[1;32m   1035\u001b[0m     tok \u001b[38;5;241m=\u001b[39m stream\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m-> 1036\u001b[0m     \u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseek\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# reset to start\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tok \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1038\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m NameObject\u001b[38;5;241m.\u001b[39mread_from_stream(stream, pdf)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "embed_model = SentenceTransformer(E5_NAME, device=DEVICE)\n",
    "REF_ITEMS = load_reference_chunks(LAW_DIR)\n",
    "REF_EMBS = embed_model.encode(\n",
    "    [it[\"text\"] for it in REF_ITEMS],\n",
    "    convert_to_tensor=True,\n",
    "    normalize_embeddings=True\n",
    ")\n",
    "print(f\"[INFO] Loaded {len(REF_ITEMS)} reference chunks.\")\n",
    "\n",
    "def search_reference(query: str, topk: int = TOPK):\n",
    "    gc.collect()  # 파이썬 객체 메모리 수거\n",
    "    with torch.cuda.device(1):\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.ipc_collect()\n",
    "    q = embed_model.encode(query, convert_to_tensor=True, normalize_embeddings=True)\n",
    "    sims = util.cos_sim(q, REF_EMBS)[0]\n",
    "    scores = [(float(s) * (1.0 + REF_ITEMS[i][\"weight\"]), i) for i, s in enumerate(sims)]\n",
    "    scores.sort(key=lambda x: x[0], reverse=True)\n",
    "    picks = []\n",
    "    for sc, idx in scores[:topk]:\n",
    "        it = REF_ITEMS[idx]\n",
    "        picks.append({\n",
    "            \"source\": it[\"source\"], \"chunk_id\": it[\"chunk_id\"],\n",
    "            \"weight\": it[\"weight\"], \"score\": round(sc, 4),\n",
    "            \"snippet\": first_n_lines(it[\"text\"], 400)\n",
    "        })\n",
    "    return picks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caf5df3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "del embed_model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56690100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.set_device(1)  # 1번 GPU 선택\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "# torch.cuda.ipc_collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98e480bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "gen_tok = AutoTokenizer.from_pretrained(\n",
    "    GEN_NAME,\n",
    "    use_fast=False,           # fast tokenizer False유지 (Local호환성 문제)\n",
    "    trust_remote_code=True\n",
    ")\n",
    "if gen_tok.pad_token_id is None:\n",
    "    gen_tok.pad_token = gen_tok.eos_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdb1c139",
   "metadata": {},
   "outputs": [],
   "source": [
    "del gen_tok\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect()\n",
    "\n",
    "time.sleep(2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cad9aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards:   0%|          | 0/3 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 260.00 MiB. GPU 1 has a total capacity of 23.69 GiB of which 12.94 MiB is free. Process 3042919 has 18.19 GiB memory in use. Including non-PyTorch memory, this process has 5.47 GiB memory in use. Of the allocated memory 4.97 GiB is allocated by PyTorch, and 213.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m gen_model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mGEN_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEVICE\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      6\u001b[0m gen_pipe \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-generation\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39mgen_model, tokenizer\u001b[38;5;241m=\u001b[39mgen_tok)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m gen_model\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:604\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    602\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mconfig_class \u001b[38;5;241m==\u001b[39m config\u001b[38;5;241m.\u001b[39msub_configs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    603\u001b[0m         config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget_text_config()\n\u001b[0;32m--> 604\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    609\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    610\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.10/site-packages/transformers/modeling_utils.py:288\u001b[0m, in \u001b[0;36mrestore_default_dtype.<locals>._wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    286\u001b[0m old_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mget_default_dtype()\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 288\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    290\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_default_dtype(old_dtype)\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.10/site-packages/transformers/modeling_utils.py:5179\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   5169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5170\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   5172\u001b[0m     (\n\u001b[1;32m   5173\u001b[0m         model,\n\u001b[1;32m   5174\u001b[0m         missing_keys,\n\u001b[1;32m   5175\u001b[0m         unexpected_keys,\n\u001b[1;32m   5176\u001b[0m         mismatched_keys,\n\u001b[1;32m   5177\u001b[0m         offload_index,\n\u001b[1;32m   5178\u001b[0m         error_msgs,\n\u001b[0;32m-> 5179\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5185\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5187\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5188\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5195\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5196\u001b[0m \u001b[38;5;66;03m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[1;32m   5197\u001b[0m model\u001b[38;5;241m.\u001b[39mtie_weights()\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.10/site-packages/transformers/modeling_utils.py:5642\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, checkpoint_files, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, device_map, disk_offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_regex, device_mesh, key_mapping, weights_only)\u001b[0m\n\u001b[1;32m   5639\u001b[0m         args_list \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mtqdm(args_list, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading checkpoint shards\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5641\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m args_list:\n\u001b[0;32m-> 5642\u001b[0m         _error_msgs, disk_offload_index, cpu_offload_index \u001b[38;5;241m=\u001b[39m \u001b[43mload_shard_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5643\u001b[0m         error_msgs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m _error_msgs\n\u001b[1;32m   5645\u001b[0m \u001b[38;5;66;03m# Adjust offloaded weights name and save if needed\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.10/site-packages/transformers/modeling_utils.py:946\u001b[0m, in \u001b[0;36mload_shard_file\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;66;03m# Skip it with fsdp on ranks other than 0\u001b[39;00m\n\u001b[1;32m    945\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_fsdp_enabled() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_local_dist_rank_0() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_quantized):\n\u001b[0;32m--> 946\u001b[0m     disk_offload_index, cpu_offload_index \u001b[38;5;241m=\u001b[39m \u001b[43m_load_state_dict_into_meta_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshard_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreverse_key_renaming_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisk_offload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcpu_offload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcpu_offload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcpu_offload_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcpu_offload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_safetensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_offloaded_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m        \u001b[49m\u001b[43munexpected_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m error_msgs, disk_offload_index, cpu_offload_index\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.10/site-packages/torch/utils/_contextlib.py:120\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 120\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.10/site-packages/transformers/modeling_utils.py:815\u001b[0m, in \u001b[0;36m_load_state_dict_into_meta_model\u001b[0;34m(model, state_dict, shard_file, expected_keys, reverse_renaming_mapping, device_map, disk_offload_folder, disk_offload_index, cpu_offload_folder, cpu_offload_index, hf_quantizer, is_safetensors, keep_in_fp32_regex, unexpected_keys, device_mesh)\u001b[0m\n\u001b[1;32m    813\u001b[0m param \u001b[38;5;241m=\u001b[39m param[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m casting_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 815\u001b[0m     param \u001b[38;5;241m=\u001b[39m \u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasting_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m to_contiguous:\n\u001b[1;32m    817\u001b[0m     param \u001b[38;5;241m=\u001b[39m param\u001b[38;5;241m.\u001b[39mcontiguous()\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 260.00 MiB. GPU 1 has a total capacity of 23.69 GiB of which 12.94 MiB is free. Process 3042919 has 18.19 GiB memory in use. Including non-PyTorch memory, this process has 5.47 GiB memory in use. Of the allocated memory 4.97 GiB is allocated by PyTorch, and 213.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "gen_model = AutoModelForCausalLM.from_pretrained(\n",
    "    GEN_NAME,\n",
    "    trust_remote_code=True,\n",
    "    device_map=DEVICE\n",
    ").eval()\n",
    "gen_pipe = pipeline(\"text-generation\", model=gen_model, tokenizer=gen_tok)\n",
    "\n",
    "del gen_model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7860e949",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embed_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m embed_model\n\u001b[1;32m      2\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[1;32m      3\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'embed_model' is not defined"
     ]
    }
   ],
   "source": [
    "del embed_model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
