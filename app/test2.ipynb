{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8390815c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alpaco/anaconda3/envs/test/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loaded 255 reference chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:33<00:00, 11.31s/it]\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 시작: VUNO Med-Chest X-ray (산업기술R&D연구기획사업)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate:   0%|          | 0/8 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generate:  12%|█▎        | 1/8 [00:37<04:22, 37.55s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generate:  25%|██▌       | 2/8 [01:09<03:24, 34.01s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generate:  38%|███▊      | 3/8 [01:43<02:50, 34.09s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generate:  50%|█████     | 4/8 [02:35<02:45, 41.32s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import tiktoken\n",
    "import os, re, json, glob, torch\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForCausalLM, pipeline,\n",
    "    AutoModelForSequenceClassification\n",
    ")\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from docx import Document\n",
    "from docx.shared import Pt\n",
    "from docx.oxml.ns import qn\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# ==============================\n",
    "# 1. 환경변수 설정\n",
    "# ==============================\n",
    "GUIDELINE_FILE = \"/home/alpaco/autosry/rnd_guideline.json\"\n",
    "RAG_JSON_FILES = [\"/home/alpaco/autosry/rag_chunks500_50.json\"]\n",
    "LAW_DIR = \"/home/alpaco/autosry/reference_file\"\n",
    "\n",
    "E5_NAME = \"intfloat/multilingual-e5-large\"\n",
    "GEN_NAME = \"skt/A.X-4.0-Light\"\n",
    "NLI_MODEL = \"MoritzLaurer/multilingual-MiniLMv2-L6-mnli-xnli\"\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# GPU 메모리 감지 → 안전 토큰 설정\n",
    "GEN_MAX_NEW_TOKENS = 3000\n",
    "if torch.cuda.is_available():\n",
    "    free, total = torch.cuda.mem_get_info()\n",
    "    if total < 12 * 1024**3:  # 12GB 미만 GPU는 토큰 수 축소\n",
    "        GEN_MAX_NEW_TOKENS = 1500\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "GEN_DO_SAMPLE = False\n",
    "\n",
    "# ==============================\n",
    "# 2. 유틸리티\n",
    "# ==============================\n",
    "def first_n_lines(text: str, n_chars=400):\n",
    "    t = \" \".join(str(text).split())\n",
    "    return t[:n_chars]\n",
    "\n",
    "def clean_generated_text(text: str) -> str:\n",
    "    text = re.sub(r'[•●▪▶◇◆□▪️▫️–]', ' ', text)\n",
    "    text = re.sub(r'^\\s*[-#*]+\\s*', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\n{3,}', '\\n\\n', text)\n",
    "    text = re.sub(r'\\s+([\\.,;:])', r'\\1', text)\n",
    "    return text.strip()\n",
    "\n",
    "def has_number(text: str):\n",
    "    return bool(re.search(r\"\\d\", text))\n",
    "\n",
    "# ==============================\n",
    "# 3. 섹션 정의 (예시 3개만)\n",
    "# ==============================\n",
    "sections = [\n",
    "    {\"section\": \"연구기획과제의 개요\",\n",
    "        \"role\": \"제안서 총괄 에디터\",\n",
    "        \"query\": \"과제의 목적, 필요성, 기대효과를 논리적으로 연결하여 핵심 내용을 500자 내외로 명료하게 요약함. 평가자가 과제의 전체 구조를 한눈에 이해할 수 있도록 기술함.\",\n",
    "        \"constraints\": [\"500자 내외\", \"논리적 연결 구조 유지\", \"핵심 요약 중심\"],\n",
    "        \"output_format\": \"서술문\"},\n",
    "    {\"section\": \"연구개발과제의 배경\",\n",
    "        \"role\": \"R&D 기획 전문가\",\n",
    "        \"query\": \"제공된 선행연구, 시장 동향, 정책자료를 근거로 본 과제가 추진되어야 하는 당위성과 RFP(공고문) 부합성을 논리적으로 제시함.\",\n",
    "        \"constraints\": [\"데이터 근거 포함\", \"RFP 문항 부합성 명시\"],\n",
    "        \"output_format\": \"서술문\"},\n",
    "    {\"section\": \"연구개발과제의 필요성\",\n",
    "        \"role\": \"산업분석가\",\n",
    "        \"query\": \"데이터와 사례를 근거로 현재 기술적·산업적 문제점을 제시하고, 본 과제가 이를 해결해야 하는 필요성을 인과적으로 서술함.\",\n",
    "        \"constraints\": [\"인과관계 구조\", \"데이터 근거 제시\"],\n",
    "        \"output_format\": \"서술문\"},\n",
    "    {\"section\": \"기술개발 핵심어(키워드)\",\n",
    "        \"role\": \"기술 네이밍 전략가\",\n",
    "        \"query\": \"과제의 정체성과 핵심 기술을 대표하는 키워드 5개를 국문·영문 공식 명칭으로 제시함. 각 용어는 국제 표준 또는 학술 정의를 근거로 하며, 선정 사유를 간단히 명시함.\",\n",
    "        \"constraints\": [\"국문·영문 병기\", \"국제 표준 기반 정의 포함\", \"5개 이내\"],\n",
    "        \"output_format\": \"표(키워드/영문명/정의/출처)\"},\n",
    "    {\"section\": \"연구개발 목표\",\n",
    "        \"role\": \"R&D PMO\",\n",
    "        \"query\": \"과제의 최종 목표를 500자 내외로 명확히 기술함. 핵심 성능지표(KPI), 달성 기준(수치·단위·마일스톤), 검증 방법을 포함하며, 모호한 표현은 사용하지 않음.\",\n",
    "        \"constraints\": [\"정량화된 수치 포함\", \"KPI 및 검증방법 명시\"],\n",
    "        \"output_format\": \"서술문 + 표(KPI/단위/기준/검증방법)\"},\n",
    "        {\"section\": \"연구개발 내용\",\n",
    "            \"role\": \"기술총괄자(Tech Lead)\",\n",
    "            \"query\": \"전체 연구 범위를 1,000자 내외로 체계적으로 기술함. 핵심 기술요소, 세부 과제 구조, 데이터 및 시스템 흐름, 성능 평가 계획을 명시함.\",\n",
    "            \"constraints\": [\"1,000자 내외\", \"기술요소 및 평가계획 포함\"],\n",
    "            \"output_format\": \"서술문 + 도식(기술흐름)\"},\n",
    "        {\"section\": \"연차별 개발목표\",\n",
    "            \"role\": \"PMO 리더\",\n",
    "            \"query\": \"최종 목표 달성을 위한 연차별 및 기관별 개발 목표를 정량적으로 제시함. 각 연차별 KPI, 마일스톤, 검증 방법을 명확히 포함함.\",\n",
    "            \"constraints\": [\"연차별 구분\", \"정량적 지표 포함\"],\n",
    "            \"output_format\": \"표(연차/KPI/마일스톤/검증방법)\"},\n",
    "        {\"section\": \"연차별 개발내용 및 범위\",\n",
    "        \"role\": \"공동연구 컨소시엄 코디네이터\",\n",
    "        \"query\": \"참여 기관별 역할, 책임, 연차별 산출물을 중복 및 누락 없이 기술함. 공동기관이 없는 경우 해당 항목은 생략함.\",\n",
    "        \"constraints\": [\"기관별 역할 명확화\", \"중복/누락 금지\"],\n",
    "        \"output_format\": \"표(기관/역할/산출물/책임)\"},\n",
    "        {\"section\": \"추진방법 및 전략\",\n",
    "            \"role\": \"총괄 아키텍트(Chief Architect)\",\n",
    "            \"query\": \"핵심 기술개발 방법론, 예측 가능한 리스크와 대응 방안, 성능 검증 계획을 논리적으로 제시함. 기술의 우수성과 실현 가능성을 입증함.\",\n",
    "            \"constraints\": [\"핵심 방법론 포함\", \"리스크 및 검증계획 명시\"],\n",
    "            \"output_format\": \"서술문 + 표(리스크/대응방안)\"},\n",
    "        {\"section\": \"과제 성과의 활용방안\",\n",
    "            \"role\": \"사업개발 총괄(BD Head)\",\n",
    "            \"query\": \"연구 성과가 실제 산업 및 시장에서 어떻게 활용될 수 있는지를 구체적으로 제시함. 목표 시장, 주요 수요처, 핵심 적용 시나리오, 기술의 차별화된 가치를 중심으로 사업화 방향을 설명함.\",\n",
    "            \"constraints\": [\"시장 시나리오 포함\", \"Value Proposition 중심\"],\n",
    "            \"output_format\": \"서술문 + 표(시장/수요처/적용시나리오)\"},\n",
    "        {\"section\": \"신규사업 신설의 기대효과\",\n",
    "            \"role\": \"거시경제 분석가(Macro-Economic Analyst)\",\n",
    "            \"query\": \"본 과제가 국가 경제에 미치는 파급효과를 정량적 지표로 제시함. 시장 창출, 수입 대체, 수출 증대, 일자리 창출 등 거시적 효과를 수치로 증명함.\",\n",
    "            \"constraints\": [\"정량적 수치 기반\", \"경제효과 명시\"],\n",
    "            \"output_format\": \"표(지표/예상값/근거자료)\"},\n",
    "        {\"section\": \"사회적 가치 창출 계획\",\n",
    "            \"role\": \"사회적 가치 전략가(Social Value Strategist)\",\n",
    "            \"query\": \"과제의 사회적 비전과 목표를 정의하고, 이를 달성하기 위한 구체적인 실행 로드맵을 수립함. 보건, 환경, 안전 등 사회적 가치 범주와 연계함.\",\n",
    "            \"constraints\": [\"사회적 가치 범주 명시\", \"로드맵 포함\"],\n",
    "            \"output_format\": \"서술문 + 표(목표/실행단계/성과지표)\"},\n",
    "        {\"section\": \"사회적 가치창출의 기대효과\",\n",
    "            \"role\": \"임팩트 평가 전문가(Impact Assessor)\",\n",
    "            \"query\": \"사회적 가치 창출 계획이 실행되었을 때 예상되는 긍정적 변화를 정량적 및 정성적 임팩트 지표로 제시함. 사회적 파급효과를 객관적으로 설명함.\",\n",
    "            \"constraints\": [\"정량/정성 지표 병기\", \"사회적 파급효과 포함\"],\n",
    "            \"output_format\": \"표(지표유형/성과/측정방법)\"},\n",
    "        {\"section\": \"경제적 성과창출의 기대효과\",\n",
    "            \"role\": \"최고재무책임자(CFO)\",\n",
    "            \"query\": \"기업 관점에서 본 과제의 재무적 성과를 구체적 수치와 함께 제시함. 예상 매출, 이익, 투자수익률(ROI), 순현재가치(NPV) 등 주요 지표를 근거와 함께 명료하게 기술함.\",\n",
    "            \"constraints\": [\"재무지표 포함\", \"산출근거 명시\"],\n",
    "            \"output_format\": \"표(지표/예상값/근거)\"},\n",
    "        {\"section\": \"신규 인력 채용 계획 및 활용 방안\",\n",
    "            \"role\": \"전략적 인사 파트너(Strategic HR Partner)\",\n",
    "            \"query\": \"과제 수행에 필요한 핵심 인력의 채용, 배치, 교육 계획을 타임라인과 함께 제시함. 인력 확보 및 역량 극대화 방안을 구체적으로 기술함.\",\n",
    "            \"constraints\": [\"타임라인 포함\", \"역량 강화 계획 명시\"],\n",
    "            \"output_format\": \"표(직무/채용시점/교육계획)\"},\n",
    "        {\"section\": \"보안등급의 분류 및 해당 사유\",\n",
    "            \"role\": \"보안관리 책임자(Security Manager)\",\n",
    "            \"query\": \"관련 법령 및 보안관리요령을 근거로 본 과제의 보안등급을 분류하고, 그 결정 사유를 간결하고 명확하게 기술함.\",\n",
    "            \"constraints\": [\"법령 근거 포함\", \"사유 명시\"],\n",
    "            \"output_format\": \"서술문\"}\n",
    "        ]\n",
    "\n",
    "# ==============================\n",
    "# 4. 임베딩 기반 RAG 인덱스 구축\n",
    "# ==============================\n",
    "CHUNK_MAX = 500\n",
    "CHUNK_OVERLAP = 50\n",
    "TOPK = 5\n",
    "REF_WEIGHTS = {\n",
    "    \"행정업무의 운영 및 혁신에 관한 규정(대통령령)\": 0.30,\n",
    "    \"행정업무의 운영 및 혁신에 관한 규정 시행규칙\": 0.30,\n",
    "    \"국가연구개발사업 연구개발계획서\": 0.20,\n",
    "    \"전략계획서 작성안내서\": 0.10,\n",
    "    \"Vertical\": 0.10\n",
    "}\n",
    "DEFAULT_WEIGHT = 0.05\n",
    "\n",
    "def guess_weight(filename: str) -> float:\n",
    "    for k, w in REF_WEIGHTS.items():\n",
    "        if k.lower() in filename.lower():\n",
    "            return w\n",
    "    return DEFAULT_WEIGHT\n",
    "\n",
    "def chunk_text(txt: str, max_chars=CHUNK_MAX, overlap=CHUNK_OVERLAP):\n",
    "    txt = \" \".join(str(txt).split())\n",
    "    chunks = []\n",
    "    i = 0\n",
    "    while i < len(txt):\n",
    "        j = min(len(txt), i + max_chars)\n",
    "        chunks.append(txt[i:j])\n",
    "        if j == len(txt): break\n",
    "        i = max(0, j - overlap)\n",
    "    return chunks\n",
    "\n",
    "def load_reference_chunks(law_dir: str):\n",
    "    items = []\n",
    "    for p in glob.glob(os.path.join(law_dir, \"*\")):\n",
    "        text = \"\"\n",
    "        try:\n",
    "            ext = p.split(\".\")[-1].lower()\n",
    "            if ext == \"pdf\":\n",
    "                reader = PdfReader(p)\n",
    "                for pg in reader.pages:\n",
    "                    text += (pg.extract_text() or \"\") + \"\\n\"\n",
    "            elif ext in (\"docx\", \"doc\"):\n",
    "                d = Document(p)\n",
    "                text = \"\\n\".join([x.text for x in d.paragraphs])\n",
    "            elif ext in (\"rtf\", \"txt\"):\n",
    "                with open(p, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "                    text = f.read()\n",
    "        except Exception:\n",
    "            continue\n",
    "        base = os.path.basename(p)\n",
    "        weight = guess_weight(base)\n",
    "        for idx, ck in enumerate(chunk_text(text)):\n",
    "            items.append({\"source\": base, \"chunk_id\": idx, \"weight\": weight, \"text\": ck})\n",
    "    return items\n",
    "\n",
    "embed_model = SentenceTransformer(E5_NAME, device=DEVICE)\n",
    "REF_ITEMS = load_reference_chunks(LAW_DIR)\n",
    "REF_EMBS = embed_model.encode(\n",
    "    [it[\"text\"] for it in REF_ITEMS],\n",
    "    convert_to_tensor=True,\n",
    "    normalize_embeddings=True\n",
    ")\n",
    "print(f\"[INFO] Loaded {len(REF_ITEMS)} reference chunks.\")\n",
    "\n",
    "def search_reference(query: str, topk: int = TOPK):\n",
    "    q = embed_model.encode(query, convert_to_tensor=True, normalize_embeddings=True)\n",
    "    sims = util.cos_sim(q, REF_EMBS)[0]\n",
    "    scores = [(float(s) * (1.0 + REF_ITEMS[i][\"weight\"]), i) for i, s in enumerate(sims)]\n",
    "    scores.sort(key=lambda x: x[0], reverse=True)\n",
    "    picks = []\n",
    "    for sc, idx in scores[:topk]:\n",
    "        it = REF_ITEMS[idx]\n",
    "        picks.append({\n",
    "            \"source\": it[\"source\"], \"chunk_id\": it[\"chunk_id\"],\n",
    "            \"weight\": it[\"weight\"], \"score\": round(sc, 4),\n",
    "            \"snippet\": first_n_lines(it[\"text\"], 400)\n",
    "        })\n",
    "    return picks\n",
    "\n",
    "def format_ctx_block(refs):\n",
    "    return \"\\n\".join([\n",
    "        f\"- [{r['source']} | w={r['weight']:.2f} | score={r['score']:.3f}]\\n  {r['snippet']}\"\n",
    "        for r in refs\n",
    "    ])\n",
    "\n",
    "# ==============================\n",
    "# 5. 생성모델 로드 \n",
    "# ==============================\n",
    "gen_tok = AutoTokenizer.from_pretrained(\n",
    "    GEN_NAME,\n",
    "    use_fast=False,           # fast tokenizer False유지 (Local호환성 문제)\n",
    "    trust_remote_code=True\n",
    ")\n",
    "if gen_tok.pad_token_id is None:\n",
    "    gen_tok.pad_token = gen_tok.eos_token\n",
    "\n",
    "gen_model = AutoModelForCausalLM.from_pretrained(\n",
    "    GEN_NAME,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\"\n",
    ").eval()\n",
    "\n",
    "gen_pipe = pipeline(\"text-generation\", model=gen_model, tokenizer=gen_tok)\n",
    "\n",
    "# ==============================\n",
    "# 6. 검증모델(NLI)\n",
    "# ==============================\n",
    "nli_tok = AutoTokenizer.from_pretrained(\"MoritzLaurer/multilingual-MiniLMv2-L6-mnli-xnli\")\n",
    "nli_model = AutoModelForSequenceClassification.from_pretrained(NLI_MODEL).to(DEVICE).eval()\n",
    "\n",
    "def nli_entail_vs_contra(premise, hypothesis):\n",
    "    inputs = nli_tok(premise, hypothesis, return_tensors=\"pt\", truncation=True, padding=True).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        logits = nli_model(**inputs).logits\n",
    "    probs = torch.softmax(logits, dim=-1).squeeze(0).tolist()\n",
    "    entail, neutral, contra = probs[0], probs[1], probs[2]\n",
    "    return entail, contra\n",
    "\n",
    "def validate_output(section_obj, generated_text: str, refs):\n",
    "    report = []\n",
    "    cleaned = generated_text.strip()\n",
    "    maxlen = 10**9\n",
    "    for c in section_obj.get(\"constraints\", []):\n",
    "        m = re.search(r\"(\\d+)\\s*자\", c)\n",
    "        if m:\n",
    "            maxlen = int(m.group(1)) + int(0.3*int(m.group(1)))\n",
    "            break\n",
    "    if len(cleaned) > maxlen:\n",
    "        report.append(f\" 길이 초과: {len(cleaned)}자 > 허용 {maxlen}자\")\n",
    "    if any(k in section_obj[\"section\"] for k in [\"목표\", \"KPI\"]) or \"정량\" in \" \".join(section_obj.get(\"constraints\", [])):\n",
    "        if not has_number(cleaned):\n",
    "            report.append(\"정량 지표(숫자) 미포함\")\n",
    "    entail_sum, contra_sum = 0.0, 0.0\n",
    "    for r in refs[:3]:\n",
    "        e, c = nli_entail_vs_contra(r[\"snippet\"], cleaned)\n",
    "        entail_sum += e; contra_sum += c\n",
    "    score = entail_sum / (entail_sum + contra_sum + 1e-6)\n",
    "    report.append(f\" NLI 정합도: {score:.2f}\")\n",
    "    if not report:\n",
    "        report.append(\" PASS-validation\")\n",
    "    return report\n",
    "\n",
    "# ==============================\n",
    "# 7. 프롬프트 구성 & 텍스트 생성\n",
    "# ==============================\n",
    "\n",
    "def build_prompt(section_obj, project_name, depart_name, project_no, period, budget):\n",
    "    # 근거문서 검색\n",
    "    refs = search_reference(section_obj[\"query\"], topk=TOPK)\n",
    "\n",
    "    # 스니펫(본문 요약문)만 추출 → 조문번호, 붙임 등 제거\n",
    "    ref_texts = \"\\n\\n\".join([r[\"snippet\"] for r in refs])\n",
    "    ref_texts = re.sub(r'붙임|끝|제\\d+조|\\(\\d{8}\\)', '', ref_texts)\n",
    "\n",
    "    return f\"\"\"\n",
    "#=========== [자동 문장 생성]\n",
    "# 역할: {section_obj['role']}\n",
    "# 작성 항목: [{section_obj['section']}]\n",
    "# 세부사업명: {depart_name}\n",
    "# 과제번호: {project_no}\n",
    "# 과제명: {project_name}\n",
    "# 기간: {period}\n",
    "# 예산: {budget} 천원\n",
    "\n",
    "# 작성 조건:\n",
    "# - 문체: '~함, ~음, ~됨' 보고서형 서술체\n",
    "# - {', '.join(section_obj['constraints'])} 준수\n",
    "# - 아래 참고내용은 단순한 참고용임. 실제 문장에 인용문이나 파일명, 점수, w=값 등을 포함하지 말 것.\n",
    "\n",
    "# 참고자료 (요약된 규정 내용)\n",
    "{ref_texts}\n",
    "\n",
    "# 요청 내용:\n",
    "# {section_obj['query']}\n",
    "#=========== [출력]:\n",
    "\"\"\".strip()\n",
    "\n",
    "def generate_text_batch(prompts, batch_size=2):\n",
    "    outputs = []\n",
    "    for i in tqdm(range(0, len(prompts), batch_size), desc=\"Generate\"):\n",
    "        chunk = prompts[i:i + batch_size]\n",
    "        out = gen_pipe(\n",
    "            chunk,\n",
    "            batch_size=batch_size,\n",
    "            max_new_tokens=GEN_MAX_NEW_TOKENS,\n",
    "            do_sample=GEN_DO_SAMPLE\n",
    "        )\n",
    "        for o in out:\n",
    "            txt = o[0][\"generated_text\"] if isinstance(o, list) else o[\"generated_text\"]\n",
    "            outputs.append(txt)\n",
    "    return outputs\n",
    "\n",
    "def clean_generated_text(text: str) -> str:\n",
    "    # ① 프롬프트 헤더/출력 지시문 전체 제거\n",
    "    text = re.sub(r'#=+.*?(자동\\s*문장\\s*생성).*?#=+', '', text, flags=re.DOTALL)\n",
    "\n",
    "    # ② ###로 시작하는 라인 제거\n",
    "    text = re.sub(r'^###.*$', '', text, flags=re.MULTILINE)\n",
    "\n",
    "    # ③ 불필요한 특수문자/공백 정리\n",
    "    text = re.sub(r'[•●▪▶◇◆□▪️▫️–]', ' ', text)\n",
    "    text = re.sub(r'^\\s*[-#*]+\\s*', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\n{3,}', '\\n\\n', text)\n",
    "    text = re.sub(r'\\s+([\\.,;:])', r'\\1', text)\n",
    "    text = re.sub(r'\\s{2,}', ' ', text)\n",
    "\n",
    "    # ④ 지시문 제거\n",
    "    text = re.sub(r'출력은\\s*본문\\s*서술문\\s*형태로\\s*작성하시오[.\\s]*', '', text)\n",
    "\n",
    "    # ⑤ 앞뒤 공백 제거\n",
    "    return text.strip()\n",
    "\n",
    "# ==============================\n",
    "# 8. DOCX 생성\n",
    "# ==============================\n",
    "def add_reference_section(doc, all_refs):\n",
    "    doc.add_page_break()\n",
    "    doc.add_heading(\"근거 법령 및 참고 문서 목록\", level=1)\n",
    "    seen = {}\n",
    "    for r in all_refs:\n",
    "        name = r['source']\n",
    "        seen[name] = seen.get(name, 0) + 1\n",
    "    for name, cnt in seen.items():\n",
    "        doc.add_paragraph(f\"- {name} (참조 {cnt}회)\")\n",
    "\n",
    "def render_doc(project_name, depart_name, project_no, period, budget):\n",
    "    doc = Document()\n",
    "    style = doc.styles['Normal']\n",
    "    font = style.font\n",
    "    font.name = '맑은 고딕'\n",
    "    font.size = Pt(11)\n",
    "    style._element.rPr.rFonts.set(qn('w:eastAsia'), '맑은 고딕')\n",
    "\n",
    "    doc.add_heading(\"R&D국가 연구 계발 계획서\", 0)\n",
    "    doc.add_paragraph(f\"세부사업명: {depart_name}\")\n",
    "    doc.add_paragraph(f\"과제명: {project_name}\")\n",
    "    doc.add_paragraph(f\"과제번호: {project_no}\")\n",
    "    doc.add_paragraph(f\"기간: {period}\")\n",
    "    doc.add_paragraph(f\"예산: {budget} 천원\\n\")\n",
    "\n",
    "    prompts = [build_prompt(s, project_name, depart_name, project_no, period, budget) for s in sections]\n",
    "    generated = generate_text_batch(prompts)\n",
    "\n",
    "    all_refs_flat = []\n",
    "\n",
    "    for sec, gen_text in zip(sections, generated):\n",
    "        doc.add_heading(sec['section'], level=1)\n",
    "        cleaned = clean_generated_text(gen_text)\n",
    "        refs = search_reference(sec[\"query\"], topk=TOPK)\n",
    "        validation = validate_output(sec, cleaned, refs)\n",
    "\n",
    "        doc.add_paragraph(cleaned)\n",
    "\n",
    "        p = doc.add_paragraph()\n",
    "        p.add_run(\"[근거문서(Top-5)]\").bold = True\n",
    "        for r in refs:\n",
    "            doc.add_paragraph(f\"- {r['source']} (w={r['weight']:.2f})\")\n",
    "\n",
    "        p = doc.add_paragraph()\n",
    "        p.add_run(\"[Eval_Result]\").bold = True\n",
    "        for v in validation:\n",
    "            doc.add_paragraph(v)\n",
    "\n",
    "        all_refs_flat.extend(refs)\n",
    "\n",
    "    add_reference_section(doc, all_refs_flat)\n",
    "    outpath = \"RND_Report.docx\"\n",
    "    doc.save(outpath)\n",
    "    print(f\"[DONE] → {outpath}\")\n",
    "\n",
    "\n",
    "\n",
    "project_name = \"VUNO Med-Chest X-ray\"\n",
    "depart_name  = \"산업기술R&D연구기획사업\"\n",
    "project_no   = \"123456789\"\n",
    "period       = \"2023.6.1 ~\"\n",
    "budget       = \"500,000\"\n",
    "print(f\"[INFO] 시작: {project_name} ({depart_name})\")\n",
    "render_doc(project_name, depart_name, project_no, period, budget)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
